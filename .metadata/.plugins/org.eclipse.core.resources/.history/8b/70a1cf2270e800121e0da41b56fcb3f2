package LDA.MAIN.INERENCE;

import java.io.BufferedWriter;
import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.ObjectInputStream;
import java.io.OutputStreamWriter;
import java.util.ArrayList;
import java.util.Map;

import edu.fudan.nlp.tag.CWSTagger;

public class Documents
{
	public ArrayList<Document> docs;
	public ArrayList<String> indexToTermMap;
	
	public Documents(String pathName,String fileName) throws FileNotFoundException, IOException, ClassNotFoundException
	{
		docs=new ArrayList<Document>();
		File file1=new File(pathName,fileName);
		ObjectInputStream ois=new ObjectInputStream(new FileInputStream(file1));
		indexToTermMap=(ArrayList<String>) ois.readObject();
		ois.close();
	}
	
	public void readDocs(String docsPath) throws Exception
	{
		File filePath=new File(docsPath);
		
		for(File f:filePath.listFiles())
		{
			Document document=new Document(docs,indexToTermMap,f);
			docs.add(document);
		}
		
	}
	
	/**
	 * 下面这个函数是想验证我们我们在inference的时候获取的index和之前获取的index是否一致
	 * @throws Exception 
	 */
	private void testInference() throws Exception
	{
		Documents documents=new Documents("./src/LDA/MAIN/serializable/","indexToTermMap.ser");
		documents.readDocs("./src/LDA/MAIN/testSet");
		
		int[] testIndex=documents.docs.get(1).docWords;
		BufferedWriter bw=new BufferedWriter(new OutputStreamWriter(new FileOutputStream("./src/LDA/MAIN/serializable/doc2_index_inference.txt")));
		for(int i=0;i<testIndex.length;i++)
			bw.write(testIndex[i]+"    ");
		bw.close();
	}
	
	
	public static class Document
	{
		public File docFile;
		public int[] docWords;
		
		public Document(ArrayList<Document> docs, ArrayList<String> indexToTermMap,File docFile) throws Exception
		{
			this.docFile=docFile;
			Long length=docFile.length();
			byte[] buffer = new byte[length.intValue()];
			FileInputStream fis=new FileInputStream(docFile);
			fis.read(buffer);
			fis.close();
			
			CWSTagger tag = new CWSTagger("./models/seg.c110722.gz");
			String str = new String(buffer);
			String s = tag.tag(str);
			String[] tokens=s.split(" ");
			
			ArrayList<Integer> wordIndexs=new ArrayList<Integer>();
			for(String token:tokens)
			{
				String temp=token.trim();
				if(indexToTermMap.contains(temp))
					wordIndexs.add(indexToTermMap.indexOf(temp));
			}
			
			
			int len=wordIndexs.size();
			docWords=new int[len];
			
			
			for(int i=0;i<len;i++)
				docWords[i]=wordIndexs.get(i);
			
		}
	}
	
	public static void main(String[] args)
	{
		Dcouments documents=new Documents("./src/LDA/MAIN/serializable/","indexToTermMap.ser");
		documents.testInference();
	}
	
	
	
}


